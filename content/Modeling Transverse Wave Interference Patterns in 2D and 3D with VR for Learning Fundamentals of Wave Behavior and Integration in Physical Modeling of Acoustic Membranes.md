---
title: Modeling Transverse Wave Interference Patterns in 2D and 3D with VR for Learning Fundamentals of Wave Behavior and Integration in Physical Modeling of Acoustic Membranes
---
Overview:
This tool's use cases split in to: audio synthesis, and visual representation. The overall project seeks to use visual models of wave interference patterns to serve as a method of physical modeling synthesis, and to serve as a learning tool in approaching wave equations.

The current implementation of this tool creates two kinds of maps to visually represent 2D transverse wave interference patterns in an ideal euclidean plane. The first is a node map, which shows emergent harmonic patterns that emerge from the waves' collision. The second is a heatmap, which shows the distribution of energy throughout the antinodes. The user can visually see these maps and manually play with the parameters to watch how the interference patterns and energy levels shift and self-organize.

To achieve physical modeling synthesis of acoustic membranes (and, possibly, wind instruments), the program would scan the data from the heatmap, then use Fourier Analysis to synthesize a series of frequency/amplitude pairings that would recreate the sound being played. By setting fixed parameters and having the program sweep through them with appropriate decay rates, this program could reasonably visually model, mathematically analyze, and sonically synthesize the sizzle of a snare drum, or the rumble of a timpani. If the program could make the leap to modeling bell-like shapes, rather than shapes in square or circular planes (which might be explored with either multivariable calculus or hyperbolic geometry, depending on the limitations of the tool's implementation), the program may be able to synthesize cymbals. The leap to modeling wind instruments may be a similar progression of the tool, probably using integration (and maybe heuristics) to represent texturally intricate sheets of air particles rising in a column of air (like a pipe organ).

The visual aspect of this project may be more interesting from a research perspective. What happens if we expand the wave equation from 2D to 3D? What happens when we make the tool a VR environment that users could roam around in as they play with the parameters? What happens if we reverse the sound synthesis process with STFTs to create an audioreactive program that can represent sounds visually as they change in a highly descriptive way? If we do this, and add an extra dimension, this would surely make for an interesting audiovisual performance art tool -- but does it have an educational use? What if we could make the program model longitudinal waves rather than transverse waves (which have different properties, like rarefactions vs. troughs)? Could we implement rules to mimic induction and use this tool to explore harmonic distortion in electric flux? I'm aware most of these questions (if not all of them) break down at a certain point for some intricacy I didn't consider -- that is why I'm so in love with this project. I don't know what those intricate details about 2D and 3D waves are, and I want to learn what they are and how they work.