The next steps of this project require me to get much better at Machine Learning (ML). The only experience I have with ML comes from [a project I did with Dr. Jeremy Wagner's guidance at Berkeley's Center for New Music and Audio Technologies (CNMAT)](obsidian://open?vault=ITPportfolio&file=Vocal%20Harmony%20Algorithms%20with%20Adapting%20Markov%20Chains%20and%20Shortest%20Paths). 


First, I would need to get a sufficient sample size of recorded audio reciting a selected text, from which I could derive a tool capable of generating a gestural pronunciation dictionary using PyToBI.

After that, I would need a sufficient sample size of a different vernacular (for example, English speakers with an Irish accent) to perform the same process with. 

As the PyToBI tool would derive faithful analytics, I would put the second tool through rigorous testing until it reached the same level of accuracy for its own vernacular. The result would be a program that could tokenize written text into either "Standard American ToBI Pronunciation" or "Standard Irish ToBI Pronunciation". 

The next step from there would be to make this process replicable for whatever vernaculars we could get the required audio samples from in order to derive an appropriate tool for them.


Without a doubt, this project will be an extremely long term one, which I will need both guidance and better technical skills for. I intend to integrate it someday into the [[Sound Sculpture]] for [[On the Map Room: Cartography as Speculative Figure Drawing for Anarchival Practice]].


#project 
backlinks: [[Gestural Measures in Vernacular and NLP]], [[Gestural Measures in Vernacular and NLP - Steps Taken]]