I began this project in an English class with Professor Flynn in my last year at Berkeley. The class was called "AIrish" and focused on combining literary analysis with methods in digital humanities with the support of Berkeley's Data Lab.

I chose to focus on using Natural Language Processing (NLP) to create visual analytics of the sonic gestures of the texts we were reading. This arose out of my interest in [the sound object in philosophy](obsidian://open?vault=ITPportfolio&file=Sound%20Sculpture) and [[The Importance of Color, the Blind, and the Deaf in Philosophy]].


My method involved using the CMU Pronunciation Dictionary to tokenize a play by W.B. Yeats and derive a ToBI representation of its sonic gestures, then contrasting that with a ToBI datamap derived from actual recitation.

My resulting findings were that the NLP tools I could access were insufficient for accurately deriving analytics solely from visual text.



#project 
backlinks: [[Gestural Measures in Vernacular and NLP]], [[Gestural Measures in Vernacular and NLP - Next Steps]]